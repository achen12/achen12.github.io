---
layout: post
title: 'A094- Robotics I: Rainbow Turtlebot Pt.2'
date: '2014-06-03T03:46:00.001-07:00'
author: Alex Chen
tags:
- Robots
- A094
- Academics
modified_time: '2014-06-03T03:46:57.131-07:00'
thumbnail: http://1.bp.blogspot.com/-QjFf-EXu5jw/U42XWB02NsI/AAAAAAAAAWk/lTjNehnzWL4/s72-c/Team3_Lab6_MapWaypoint.png
blogger_id: tag:blogger.com,1999:blog-6553736778655057698.post-7163651517789927046
blogger_orig_url: http://scientificventure.blogspot.com/2014/06/a094-robotics-i-rainbow-turtlebot-pt2.html
---

In Robotics I (6.141), we where tasked to complete a standard RSS robot.&nbsp; My team includes...<br />Ami Greene<br />Clark Della Silva<br />Eric Van Albert<br />William Kalb <br />And Me!<br />(I'll try to find their blog address and link them in.)<br /><br />So what does a standard RSS robot include?&nbsp; All it is, is a camera, a servo arm with a big gripper, two wheels, and a laptop.&nbsp; So what can an RSS robot do?&nbsp; We built modules lab over lab, to implement new abilities to the robot.&nbsp; Initially, the robot could to semi-autonomous tasks like travel to a particular distance,&nbsp; or rotate to a particular distance.&nbsp; It does this by reading the encoder on the wheels and controlling them properly.&nbsp; And in the end, the RSS bot can navigate within a maze with a given map, identify a cube with a specific color, and approach a cube and pick it up.<br /><br />To navigate around a maze, we have to use a navigation technique called C-Space.&nbsp; C-Space or configuration space, is a mean to analyze a given map relative to a robot.&nbsp; Instead of symbolizing the robot as a complex geometry, and calculate its path around the 2D map.&nbsp; We'll expand the 2D map to half of the width of the robot, and reduce the robot to a single point.&nbsp; This expanded map is the configuration space, i.e. the possible space that the robot can occupy.&nbsp; As shown here.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-QjFf-EXu5jw/U42XWB02NsI/AAAAAAAAAWk/lTjNehnzWL4/s1600/Team3_Lab6_MapWaypoint.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-QjFf-EXu5jw/U42XWB02NsI/AAAAAAAAAWk/lTjNehnzWL4/s1600/Team3_Lab6_MapWaypoint.png" height="320" width="252" /></a></div>The original map is marked in black.&nbsp; And the red outline is the C-Space.&nbsp; In this image, the robot is actually running a course from left bottom to the upper right corner of the map.&nbsp; The purple/pink line is the path it has chosen to navigate in.&nbsp; As you can see, the robot used the C-Space to figure out what is the shortest path it could take, and the path line often contact the C-Space when the robot is going to turn (Essentially to get the sharpest turn to approach the goal).&nbsp; Some other artifacts are also present.&nbsp; The blue square represents the corners that the robot has successfully cleared.&nbsp; The green outline is where the robot is currently at, and the grey outline is where the robot was at.<br /><br />Well,&nbsp; that's pretty awesome... How about identifying the cubes?&nbsp; It does this through the webcam.&nbsp; The webcam receives video stream data in the form of RGB.&nbsp; First, to analytic purposes, we are going to convert the stream to HSV (Brightness, Saturation, and Value).&nbsp; This is critical because instead of having the data evaluated by how red, green and blue it is, we are evaluating each pixel by how white is it, how colorful is it, and what color is it.&nbsp; Thus it will be easier for us to filter out the red pixels of a red cube.&nbsp;&nbsp; After we have all the red pixel, we can work some visual filter magic:&nbsp; blog detection (identifying the biggest blob of the selected pixels), moment calculation&amp;edge detection (being able to calculate the shape of the blob).&nbsp; Thus, we can select which blob of pixels are of a red cube.&nbsp; To show this, I've included a picture of the camera feed.&nbsp; Unfortunately, I couldn't find a good picture <br />with the HSV filter, but the RGB filter works on the same principle.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-Eig0b249pZw/U42ejPiteBI/AAAAAAAAAW0/DLZNjugz09A/s1600/Team3_Lab3_WithBallRGB.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-Eig0b249pZw/U42ejPiteBI/AAAAAAAAAW0/DLZNjugz09A/s1600/Team3_Lab3_WithBallRGB.png" height="246" width="320" /></a></div>The background is in black and white.&nbsp; We've colored the pixels filtered out in red.&nbsp; For sanity purposes, we also included a RGB histogram on the bottom left.&nbsp; Just so that we can see what is going on.&nbsp; To simplify the problem in the beginning we used balls instead of cubes.&nbsp; As you can see, in the picture the robot has identified and place a green frame on the ball even when the ball isn't in full view.&nbsp; It uses the curvature of the blob, and deduced that the shape is a circle=&gt;cube.<br /><br />Finally, we come to the gripper.&nbsp; The gripper arm is composed of a shoulder joint (control the angle of the arm), a wrist joint (the angle of the hand), and a gripping joint (the angle of the fingers).&nbsp; Essentially we control the angles of each joint, and allow the control loop inside each servo to determine the force it should use.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-0Gzhf6eoIeY/U42kAIlQSpI/AAAAAAAAAXE/mWeVQ4-hLH0/s1600/picture000.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-0Gzhf6eoIeY/U42kAIlQSpI/AAAAAAAAAXE/mWeVQ4-hLH0/s1600/picture000.jpg" height="180" width="320" /></a></div><br /><div style="text-align: center;">Here is robot with an arm and camera.</div><div style="text-align: left;">And that's the RSS robot, that we spent first half of the semester building.&nbsp; Now onto the course's main core - The Grand Challenge.&nbsp; Our robot will land on Mars (Model Mars... i.e. a Maze) with cubes (living quarter modules) landed all around us.&nbsp; Our objective is to have the robot collect the modules and build a small structure with it before the astronauts landed (in 10 minutes).&nbsp; Now.... How could we make this robot in 4 weeks to do that?....</div>